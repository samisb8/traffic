import json
import shutil
from datetime import datetime
from pathlib import Path

import joblib
import mlflow
import mlflow.sklearn
import requests


def cleanup_mlflow_runs():
    """Nettoie tous les runs MLflow ouverts"""
    try:
        while mlflow.active_run():
            mlflow.end_run()
    except Exception:
        pass


def load_metrics(model_path):
    """Charge les m√©triques d'un mod√®le"""
    metrics_path = model_path.parent / "model_metrics.json"
    if metrics_path.exists():
        with open(metrics_path) as f:
            return json.load(f)
    return None


def compare_models():
    """Compare nouveau mod√®le vs mod√®le en production"""
    # Nouveau mod√®le
    new_model_path = Path("data/model.pkl")
    new_metrics = load_metrics(new_model_path)

    # Mod√®le en production
    prod_model_path = Path("data/model_production.pkl")
    prod_metrics_path = Path("data/model_production_metrics.json")

    if not prod_model_path.exists():
        print("üÜï Aucun mod√®le en production, d√©ploiement du nouveau")
        return True, new_metrics, None

    if prod_metrics_path.exists():
        with open(prod_metrics_path) as f:
            prod_metrics = json.load(f)
    else:
        print("‚ö†Ô∏è  M√©triques production manquantes")
        return True, new_metrics, None

    # Comparaison (crit√®re: accuracy)
    new_accuracy = new_metrics.get("accuracy", 0)
    prod_accuracy = prod_metrics.get("accuracy", 0)

    print(f"üìä Comparaison mod√®les:")
    print(f"   Nouveau: {new_accuracy:.4f}")
    print(f"   Production: {prod_accuracy:.4f}")

    should_deploy = new_accuracy >= prod_accuracy  # CHANG√â: >= au lieu de >
    return should_deploy, new_metrics, prod_metrics


def log_model_to_mlflow(model_path, metrics):
    """Enregistre le mod√®le dans MLflow avec gestion d'erreurs"""
    try:
        # Nettoyage pr√©ventif
        cleanup_mlflow_runs()

        # CORRECTION: Utiliser le bon port MLflow
        mlflow.set_tracking_uri("http://localhost:5001")  # 5001 au lieu de 5000
        mlflow.set_experiment("Traffic_Prediction")

        with mlflow.start_run(
            run_name=f"deployment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        ):
            # Log des param√®tres
            model_type = metrics.get("model_type", "Unknown")
            mlflow.log_param("model_type", model_type)
            mlflow.log_param("location", "Casablanca, Morocco")
            mlflow.log_param("deployment_time", datetime.now().isoformat())
            mlflow.log_param("deployment_status", "success")
            mlflow.log_param("deployment_trigger", "automated")

            # Log des m√©triques de performance
            performance_metrics = {
                "accuracy": metrics.get("accuracy", 0),
                "mae": metrics.get("mae", 0),
                "r2_score": metrics.get("r2_score", 0),
                "rmse": metrics.get("rmse", 0) if "rmse" in metrics else None,
            }

            for metric_name, value in performance_metrics.items():
                if value is not None and isinstance(value, (int, float)):
                    mlflow.log_metric(f"deployed_{metric_name}", value)

            # Log toutes les autres m√©triques num√©riques
            for metric_name, value in metrics.items():
                if (
                    isinstance(value, (int, float))
                    and metric_name not in performance_metrics
                ):
                    try:
                        mlflow.log_metric(metric_name, value)
                    except:
                        pass  # Ignorer les erreurs de m√©triques

            # V√©rifier que le mod√®le existe
            if not model_path.exists():
                raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")

            # Charger et log du mod√®le
            model = joblib.load(model_path)
            mlflow.sklearn.log_model(
                sk_model=model,
                artifact_path="deployed_traffic_model",
                registered_model_name="CasablancaTrafficModel_Production",
            )

            # Log des artefacts suppl√©mentaires (avec v√©rification)
            artifacts_to_log = [
                "data/model_metrics.json",
                "data/traffic_data.csv",
                "data/all_models_results.json",  # Si multi-mod√®les
            ]

            for artifact_path in artifacts_to_log:
                if Path(artifact_path).exists():
                    try:
                        mlflow.log_artifact(artifact_path)
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Erreur log artefact {artifact_path}: {e}")
                else:
                    print(f"‚ö†Ô∏è  Artefact non trouv√©: {artifact_path}")

            print("‚úÖ Mod√®le enregistr√© dans MLflow avec succ√®s")
            return True

    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur MLflow: {e}")
        print("üîÑ D√©ploiement continue sans MLflow...")
        return False


def deploy_model():
    """D√©ploie le nouveau mod√®le si meilleur"""
    print("üöÄ D√©but d√©ploiement mod√®le...")

    # Nettoyage initial
    cleanup_mlflow_runs()

    # V√©rification nouveau mod√®le
    new_model_path = Path("data/model.pkl")
    if not new_model_path.exists():
        print("‚ùå Aucun nouveau mod√®le trouv√©")
        print("üí° Lancez d'abord: python mlops/train.py")
        return False

    # Charger les m√©triques du nouveau mod√®le
    new_metrics = load_metrics(new_model_path)
    if not new_metrics:
        print("‚ùå M√©triques du nouveau mod√®le non trouv√©es")
        print("üí° Le fichier model_metrics.json est requis")
        return False

    # Afficher info du nouveau mod√®le
    print(f"üìä Nouveau mod√®le d√©tect√©:")
    print(f"   Type: {new_metrics.get('model_type', 'Unknown')}")
    print(f"   Accuracy: {new_metrics.get('accuracy', 0):.4f}")
    print(f"   Entra√Æn√© le: {new_metrics.get('training_date', 'Unknown')}")

    # Comparaison avec le mod√®le en production
    should_deploy, new_metrics, prod_metrics = compare_models()

    if not should_deploy:
        print("‚ùå Nouveau mod√®le ne respecte pas les crit√®res de d√©ploiement")
        improvement = new_metrics.get("accuracy", 0) - (
            prod_metrics.get("accuracy", 0) if prod_metrics else 0
        )
        print(f"üìâ Am√©lioration requise: {improvement:.4f}")
        return False

    deployment_success = False

    try:
        # 1. Tentative d'enregistrement dans MLflow (non bloquant)
        print("üìä Tentative d'enregistrement dans MLflow...")
        mlflow_success = log_model_to_mlflow(new_model_path, new_metrics)

        if not mlflow_success:
            print("‚ö†Ô∏è  MLflow indisponible, d√©ploiement local seulement")

        # 2. Backup mod√®le actuel
        prod_model_path = Path("data/model_production.pkl")
        if prod_model_path.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = Path(f"data/backups/model_backup_{timestamp}.pkl")
            backup_path.parent.mkdir(exist_ok=True, parents=True)
            shutil.copy2(prod_model_path, backup_path)
            print(f"üíæ Backup cr√©√©: {backup_path}")

        # 3. D√©ploiement du nouveau mod√®le
        print("üîÑ Copie du mod√®le en production...")
        shutil.copy2(new_model_path, prod_model_path)
        shutil.copy2("data/model_metrics.json", "data/model_production_metrics.json")

        print("‚úÖ Mod√®le d√©ploy√© en production!")
        print(f"üéØ Nouvelle accuracy: {new_metrics.get('accuracy', 'N/A'):.4f}")
        print(f"üìä MAE: {new_metrics.get('mae', 'N/A'):.4f}")
        print(f"üìà R¬≤: {new_metrics.get('r2_score', 'N/A'):.4f}")

        deployment_success = True

        # 4. Historique de d√©ploiement
        deployment_info = {
            "deployment_time": datetime.now().isoformat(),
            "model_type": new_metrics.get("model_type", "Unknown"),
            "accuracy": new_metrics.get("accuracy", 0),
            "mae": new_metrics.get("mae", 0),
            "r2_score": new_metrics.get("r2_score", 0),
            "mlflow_logged": mlflow_success,
            "previous_accuracy": prod_metrics.get("accuracy", 0) if prod_metrics else 0,
        }

        # Sauvegarder historique
        history_path = Path("data/deployment_history.json")
        if history_path.exists():
            with open(history_path) as f:
                history = json.load(f)
        else:
            history = []

        history.append(deployment_info)

        with open(history_path, "w") as f:
            json.dump(history, f, indent=2)

        print(f"üìù Historique mis √† jour: {len(history)} d√©ploiements")

        # 5. Notification API (optionnel, non bloquant)
        try:
            print("üîÑ Notification de l'API...")
            response = requests.post(
                "http://localhost:8000/model-updated",
                json={
                    "status": "success",
                    "metrics": new_metrics,
                    "deployment_time": datetime.now().isoformat(),
                    "model_type": new_metrics.get("model_type", "Unknown"),
                },
                timeout=10,
            )

            if response.status_code == 200:
                print("‚úÖ API notifi√©e du nouveau mod√®le")
            else:
                print(f"‚ö†Ô∏è  API notification √©chou√©e: {response.status_code}")

        except requests.exceptions.ConnectionError:
            print("‚ö†Ô∏è  API non accessible (normal si backend arr√™t√©)")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur notification API: {e}")

        return True

    except Exception as e:
        print(f"‚ùå Erreur critique d√©ploiement: {e}")

        # Tentative de restauration si √©chec
        if deployment_success:
            print("üîÑ Tentative de restauration...")
            # Logique de rollback si n√©cessaire

        return False


def verify_deployment():
    """V√©rifie que le d√©ploiement s'est bien pass√©"""
    prod_model_path = Path("data/model_production.pkl")
    prod_metrics_path = Path("data/model_production_metrics.json")

    if prod_model_path.exists() and prod_metrics_path.exists():
        print("‚úÖ V√©rification d√©ploiement: OK")

        # Charger et tester le mod√®le rapidement
        try:
            model = joblib.load(prod_model_path)
            print(f"‚úÖ Mod√®le chargeable: {type(model).__name__}")

            with open(prod_metrics_path) as f:
                metrics = json.load(f)
                print(f"‚úÖ M√©triques production: {metrics.get('accuracy', 'N/A'):.4f}")
                print(f"‚úÖ Type mod√®le: {metrics.get('model_type', 'Unknown')}")

            # Test de pr√©diction rapide
            import numpy as np

            test_input = np.array([[8, 1, 0.8, 0.1, 0.6]])  # Heure de pointe
            prediction = model.predict(test_input)[0]
            print(f"‚úÖ Test pr√©diction: {prediction:.3f}")

            return True
        except Exception as e:
            print(f"‚ùå Erreur v√©rification: {e}")
            return False
    else:
        print("‚ùå V√©rification d√©ploiement: √âCHEC")
        return False


if __name__ == "__main__":
    # Nettoyage initial
    cleanup_mlflow_runs()

    # Configuration MLflow (avec gestion d'erreur)
    try:
        # CORRECTION: Utiliser le bon port
        mlflow.set_tracking_uri("http://localhost:5001")  # 5001 au lieu de 5000
        mlflow.set_experiment("Traffic_Prediction")
        print("‚úÖ Exp√©rience MLflow configur√©e (port 5001)")
    except Exception as e:
        print(f"‚ö†Ô∏è  MLflow non disponible: {e}")

    # Ex√©cution du d√©ploiement
    print("=" * 50)
    success = deploy_model()
    print("=" * 50)

    if success:
        print("üéâ D√©ploiement r√©ussi!")

        # V√©rification post-d√©ploiement
        if verify_deployment():
            print("üèÜ Mod√®le op√©rationnel en production!")
            print("üìä V√©rifiez MLflow: http://localhost:5001")
        else:
            print("‚ö†Ô∏è  Probl√®me d√©tect√© apr√®s d√©ploiement")
    else:
        print("üí• D√©ploiement √©chou√©!")
        print("üîß Solutions possibles:")
        print("   1. V√©rifiez que train.py a √©t√© ex√©cut√©")
        print("   2. Red√©marrez MLflow: python -m mlflow ui --port 5001")
        print("   3. V√©rifiez les permissions sur le dossier data/")
