import argparse
from datetime import datetime, timedelta
from pathlib import Path

import joblib
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split


def load_data():
    """Charge ou g√©n√®re donn√©es de trafic"""
    data_path = Path("data/traffic_data.csv")

    if data_path.exists():
        try:
            print("üìä Chargement donn√©es existantes")
            df = pd.read_csv(data_path)
            if len(df) > 0 and all(
                col in df.columns
                for col in [
                    "hour",
                    "day_of_week",
                    "weather_score",
                    "event_impact",
                    "historical_avg",
                    "traffic_level",
                ]
            ):
                print(f"‚úÖ Donn√©es valides charg√©es: {len(df)} √©chantillons")
                return df
            else:
                print("‚ö†Ô∏è Donn√©es invalides, r√©g√©n√©ration...")
                return generate_casablanca_traffic_data()
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lecture: {e}, r√©g√©n√©ration...")
            return generate_casablanca_traffic_data()
    else:
        print("üìä G√©n√©ration nouvelles donn√©es Casablanca")
        return generate_casablanca_traffic_data()


def generate_casablanca_traffic_data():
    """G√©n√®re donn√©es r√©alistes de trafic pour Casablanca"""
    print("üá≤üá¶ G√©n√©ration donn√©es trafic Casablanca...")

    np.random.seed(42)

    # Zones strat√©giques de Casablanca
    casablanca_zones = {
        "Centre_Ville": {
            "business_factor": 1.2,
            "rush_multiplier": 1.8,
            "weekend_factor": 0.6,
            "base_traffic": 0.65,
        },
        "Maarif": {
            "business_factor": 1.1,
            "rush_multiplier": 1.6,
            "weekend_factor": 0.8,
            "base_traffic": 0.55,
        },
        "Anfa": {
            "business_factor": 0.9,
            "rush_multiplier": 1.4,
            "weekend_factor": 0.9,
            "base_traffic": 0.45,
        },
        "Sidi_Bernoussi": {
            "business_factor": 1.3,
            "rush_multiplier": 1.7,
            "weekend_factor": 0.4,
            "base_traffic": 0.6,
        },
        "Hay_Hassani": {
            "business_factor": 0.8,
            "rush_multiplier": 1.5,
            "weekend_factor": 0.7,
            "base_traffic": 0.4,
        },
        "Ain_Sebaa": {
            "business_factor": 1.4,
            "rush_multiplier": 1.9,
            "weekend_factor": 0.3,
            "base_traffic": 0.7,
        },
    }

    # G√©n√©ration sur 60 jours pour avoir suffisamment de donn√©es
    data = []
    start_date = datetime.now() - timedelta(days=60)

    for day in range(60):
        current_date = start_date + timedelta(days=day)
        day_of_week = current_date.weekday()  # 0=Lundi, 6=Dimanche

        # Facteurs sp√©ciaux pour Casablanca
        is_friday = day_of_week == 4  # Vendredi = jour de pri√®re
        is_weekend = day_of_week >= 5  # Samedi-Dimanche
        is_ramadan = day % 30 < 3  # Simulation p√©riode Ramadan (3 jours sur 30)

        for hour in range(24):
            for zone_name, zone_info in casablanca_zones.items():

                # === PATTERNS HORAIRES CASABLANCA ===
                # Heures de pointe matinales (7h-9h)
                morning_rush = 1.0 + 0.8 * np.exp(-((hour - 8) ** 2) / 2)

                # Heures de pointe du soir (17h-19h)
                evening_rush = 1.0 + 0.9 * np.exp(-((hour - 18) ** 2) / 2)

                # Pause d√©jeuner (12h-14h)
                lunch_factor = 1.0 + 0.3 * np.exp(-((hour - 13) ** 2) / 4)

                # Trafic nocturne tr√®s faible
                if hour >= 23 or hour <= 5:
                    night_factor = 0.1 + 0.1 * np.random.random()
                else:
                    night_factor = 1.0

                # === FACTEURS M√âT√âO CASABLANCA ===
                # M√©t√©o oc√©anique: plus de pluie en hiver
                month = (day // 30) % 12
                if month in [0, 1, 2, 10, 11]:  # Hiver
                    rain_probability = 0.3
                    weather_impact = np.random.choice(
                        [0.7, 1.0], p=[rain_probability, 1 - rain_probability]
                    )
                else:  # √ât√©
                    weather_impact = np.random.uniform(0.9, 1.0)

                weather_score = weather_impact

                # === √âV√âNEMENTS SP√âCIAUX CASABLANCA ===
                event_impact = 0.0

                # Matchs Raja/Wydad (stade Mohammed V)
                if np.random.random() < 0.05:  # 5% chance match important
                    if 19 <= hour <= 23:  # Soir
                        event_impact = 0.4

                # Festivals/√©v√©nements culturels
                if np.random.random() < 0.02:  # 2% chance √©v√©nement
                    event_impact = 0.3

                # Manifestations/gr√®ves (rare mais impact fort)
                if np.random.random() < 0.01:  # 1% chance
                    event_impact = 0.6

                # === CALCUL TRAFIC FINAL ===
                base_traffic = zone_info["base_traffic"]

                # Application des facteurs
                traffic_level = base_traffic
                traffic_level *= morning_rush * evening_rush * lunch_factor
                traffic_level *= zone_info["business_factor"]
                traffic_level *= night_factor

                # Ajustements sp√©ciaux Casablanca
                if is_weekend:
                    traffic_level *= zone_info["weekend_factor"]

                if is_friday and 11 <= hour <= 14:  # Pri√®re du vendredi
                    traffic_level *= 1.3

                if is_ramadan:
                    if 4 <= hour <= 6:  # Sahur
                        traffic_level *= 1.4
                    elif 17 <= hour <= 20:  # Iftar
                        traffic_level *= 1.6
                    else:
                        traffic_level *= 0.8

                # Impact m√©t√©o et √©v√©nements
                traffic_level *= weather_score
                traffic_level += event_impact

                # Bruit r√©aliste
                traffic_level += np.random.normal(0, 0.05)

                # Normalisation
                traffic_level = np.clip(traffic_level, 0, 1)

                # Calcul moyenne historique (simulation)
                historical_avg = base_traffic * zone_info["business_factor"] * 0.9
                if is_weekend:
                    historical_avg *= zone_info["weekend_factor"]
                historical_avg = np.clip(
                    historical_avg + np.random.normal(0, 0.02), 0, 1
                )

                # Ajout des donn√©es
                data.append(
                    {
                        "hour": hour,
                        "day_of_week": day_of_week,
                        "weather_score": round(weather_score, 3),
                        "event_impact": round(event_impact, 3),
                        "historical_avg": round(historical_avg, 3),
                        "traffic_level": round(traffic_level, 3),
                        # Donn√©es suppl√©mentaires pour analyse (optionnel)
                        "zone": zone_name,
                        "is_weekend": is_weekend,
                        "is_ramadan": is_ramadan,
                        "timestamp": current_date.replace(hour=hour),
                    }
                )

    df = pd.DataFrame(data)

    # Garder seulement les colonnes n√©cessaires pour le mod√®le
    model_df = df[
        [
            "hour",
            "day_of_week",
            "weather_score",
            "event_impact",
            "historical_avg",
            "traffic_level",
        ]
    ].copy()

    # Sauvegarde
    Path("data").mkdir(exist_ok=True)
    model_df.to_csv("data/traffic_data.csv", index=False)

    # Sauvegarde donn√©es compl√®tes pour analyse
    df.to_csv("data/casablanca_full_data.csv", index=False)

    print(f"‚úÖ Donn√©es Casablanca g√©n√©r√©es: {len(model_df)} √©chantillons")
    print(f"üìä Zones couvertes: {df['zone'].nunique()}")
    print(
        f"üìÖ P√©riode: {df['timestamp'].min().date()} √† {df['timestamp'].max().date()}"
    )
    print(f"üöó Trafic moyen: {model_df['traffic_level'].mean():.3f}")
    print(
        f"‚ö° Heures de pointe d√©tect√©es: {(model_df['traffic_level'] > 0.8).sum()} cas"
    )

    return model_df


def cleanup_mlflow_runs():
    """Nettoie tous les runs MLflow ouverts"""
    try:
        while mlflow.active_run():
            mlflow.end_run()
    except Exception:
        pass


def train_model(test_mode=False):
    """Entra√Æne le mod√®le de pr√©diction trafic"""
    print("ü§ñ D√©but entra√Ænement mod√®le...")

    # Nettoyage MLflow
    cleanup_mlflow_runs()

    # Chargement donn√©es
    df = load_data()

    print(f"üìä Dataset charg√©: {len(df)} √©chantillons")
    print("üìà Statistiques trafic:")
    print(f"   Minimum: {df['traffic_level'].min():.3f}")
    print(f"   Maximum: {df['traffic_level'].max():.3f}")
    print(f"   Moyenne: {df['traffic_level'].mean():.3f}")
    print(f"   M√©diane: {df['traffic_level'].median():.3f}")

    # Pr√©paration features
    features = [
        "hour",
        "day_of_week",
        "weather_score",
        "event_impact",
        "historical_avg",
    ]
    X = df[features]
    y = df["traffic_level"]

    # V√©rification donn√©es
    print("üîç V√©rification donn√©es:")
    print(f"   Features shape: {X.shape}")
    print(f"   Target shape: {y.shape}")
    print(f"   Valeurs manquantes: {X.isnull().sum().sum()}")

    # Split train/test stratifi√© par niveau de trafic
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=pd.cut(y, bins=5, labels=False)
    )

    # Mod√®le
    if test_mode:
        model = RandomForestRegressor(
            n_estimators=50, max_depth=10, random_state=42
        )  # Rapide pour tests
        print("üß™ Mode test: mod√®le simplifi√©")
    else:
        model = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
        )
        print("üöÄ Mode production: mod√®le optimis√©")

    # Entra√Ænement
    print("üîÑ Entra√Ænement en cours...")
    model.fit(X_train, y_train)

    # √âvaluation
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    # M√©triques train
    mae_train = mean_absolute_error(y_train, y_pred_train)
    r2_train = r2_score(y_train, y_pred_train)

    # M√©triques test
    mae_test = mean_absolute_error(y_test, y_pred_test)
    r2_test = r2_score(y_test, y_pred_test)

    # Accuracy approximative (1 - erreur normalis√©e)
    accuracy_train = max(0, 1 - mae_train)
    accuracy_test = max(0, 1 - mae_test)

    # Importance des features
    feature_importance = dict(zip(features, model.feature_importances_))

    metrics = {
        "mae_train": round(mae_train, 4),
        "mae_test": round(mae_test, 4),
        "r2_train": round(r2_train, 4),
        "r2_test": round(r2_test, 4),
        "accuracy_train": round(accuracy_train, 4),
        "accuracy_test": round(accuracy_test, 4),
        "accuracy": round(accuracy_test, 4),  # Pour compatibilit√©
        "mae": round(mae_test, 4),  # Pour compatibilit√©
        "r2_score": round(r2_test, 4),  # Pour compatibilit√©
        "n_samples": len(df),
        "n_features": len(features),
        "features": features,
        "feature_importance": {k: round(v, 4) for k, v in feature_importance.items()},
        "model_type": "RandomForestRegressor",
        "location": "Casablanca, Morocco",
        "training_date": datetime.now().isoformat(),
    }

    print("\nüìä R√©sultats d'entra√Ænement:")
    print(f"   üéØ Accuracy Test: {accuracy_test:.4f} ({accuracy_test*100:.1f}%)")
    print(f"   üìâ MAE Test: {mae_test:.4f}")
    print(f"   üìà R¬≤ Test: {r2_test:.4f}")
    print("\nüîß Importance des features:")
    for feature, importance in sorted(
        feature_importance.items(), key=lambda x: x[1], reverse=True
    ):
        print(f"   {feature}: {importance:.4f}")

    # D√©tection overfitting
    if r2_train - r2_test > 0.1:
        print("‚ö†Ô∏è  Possible overfitting d√©tect√©!")
    else:
        print("‚úÖ Pas d'overfitting d√©tect√©")

    # Sauvegarde mod√®le
    model_path = Path("data/model.pkl")
    model_path.parent.mkdir(exist_ok=True)
    joblib.dump(model, model_path)

    # Sauvegarde m√©triques
    with open("data/model_metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)

    print(f"\nüíæ Mod√®le sauv√©: {model_path}")
    print("üìã M√©triques sauv√©es: data/model_metrics.json")

    # ========== AJOUT MLFLOW TRACKING ==========
    try:
        print("üìä Enregistrement dans MLflow...")

        # Configuration MLflow
        mlflow.set_experiment("Traffic_Prediction")

        with mlflow.start_run(
            run_name=f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        ):
            # Log des param√®tres du mod√®le
            if test_mode:
                mlflow.log_params(
                    {
                        "n_estimators": 50,
                        "max_depth": 10,
                        "mode": "test",
                        "random_state": 42,
                    }
                )
            else:
                mlflow.log_params(
                    {
                        "n_estimators": 200,
                        "max_depth": 15,
                        "min_samples_split": 5,
                        "min_samples_leaf": 2,
                        "mode": "production",
                        "random_state": 42,
                    }
                )

            # Log des param√®tres g√©n√©raux
            mlflow.log_params(
                {
                    "model_type": "RandomForestRegressor",
                    "location": "Casablanca, Morocco",
                    "n_samples": len(df),
                    "n_features": len(features),
                    "zones_count": 6,
                    "test_size": 0.2,
                    "stratified": True,
                }
            )

            # Log de TOUTES les m√©triques
            mlflow.log_metrics(
                {
                    "accuracy_train": accuracy_train,
                    "accuracy_test": accuracy_test,
                    "accuracy": accuracy_test,  # M√©trique principale
                    "mae_train": mae_train,
                    "mae_test": mae_test,
                    "mae": mae_test,
                    "r2_train": r2_train,
                    "r2_test": r2_test,
                    "r2_score": r2_test,
                    "overfitting_score": r2_train - r2_test,
                }
            )

            # Log importance des features
            for feature, importance in feature_importance.items():
                mlflow.log_metric(f"feature_importance_{feature}", importance)

            # Log du mod√®le sklearn
            mlflow.sklearn.log_model(
                model, "traffic_model", registered_model_name="CasablancaTrafficModel"
            )

            # Log des artefacts
            mlflow.log_artifact("data/model_metrics.json")
            if Path("data/traffic_data.csv").exists():
                mlflow.log_artifact("data/traffic_data.csv")
            if Path("data/casablanca_full_data.csv").exists():
                mlflow.log_artifact("data/casablanca_full_data.csv")

            print("‚úÖ Mod√®le enregistr√© dans MLflow")

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur MLflow (non bloquante): {e}")
        print("üíæ Mod√®le sauv√© localement quand m√™me")

    return metrics


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Entra√Ænement mod√®le trafic Casablanca"
    )
    parser.add_argument("--test-mode", action="store_true", help="Mode test (rapide)")
    parser.add_argument(
        "--regenerate", action="store_true", help="Forcer r√©g√©n√©ration donn√©es"
    )
    args = parser.parse_args()

    # Forcer r√©g√©n√©ration si demand√©
    if args.regenerate:
        print("üîÑ R√©g√©n√©ration forc√©e des donn√©es...")
        df = generate_casablanca_traffic_data()

    # Configuration MLflow
    try:
        mlflow.set_experiment("Traffic_Prediction")
        print("‚úÖ Exp√©rience MLflow configur√©e")
    except Exception as e:
        print(f"‚ö†Ô∏è MLflow non disponible: {e}")

    # Entra√Ænement
    try:
        metrics = train_model(test_mode=args.test_mode)
        print("\nüéâ Entra√Ænement termin√© avec succ√®s!")
        print(f"üèÜ Performance finale: {metrics['accuracy']:.1%}")
        print("üìä V√©rifiez MLflow: http://localhost:5001")
    except Exception as e:
        print(f"\nüí• Erreur lors de l'entra√Ænement: {e}")
        print("üÜò Essayez: python mlops/train.py --regenerate")
        exit(1)
